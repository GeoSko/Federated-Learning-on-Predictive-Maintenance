{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lstm pytorch syft remote execution (centralized).ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1xRkT8o3k2d7duxuqByRvpW-Tv0emLc-a","authorship_tag":"ABX9TyMukJwpCW1tE6X8TxolXNER"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# !pip install syft==0.5.0\n","# !pip install torch==1.8.1"],"metadata":{"id":"79RlCX5x2RFH"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ac9TzbFuFjct"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","from sklearn.model_selection import GroupShuffleSplit\n","from sklearn.metrics import confusion_matrix, classification_report\n","\n","import syft as sy\n","import torch as th\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader"]},{"cell_type":"code","source":["alice = sy.VirtualMachine(name=\"alice\")\n","bob = sy.VirtualMachine(name=\"bob\")\n","\n","alice_client = alice.get_root_client()\n","alice_torch = alice_client.torch\n","\n","bob_client = bob.get_root_client()\n","bob_torch = alice_client.torch\n","\n","clients = []\n","clients.append({'hook': alice_client})\n","clients.append({'hook': bob_client})\n","\n","clients[0]['torch'] = alice_torch\n","clients[1]['torch'] = bob_torch"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1631169943960},"id":"KlX3iSLVefda"}},{"cell_type":"code","source":["path = \"/content/drive/MyDrive/Thesis/Datasets/Turbofan_Dataset/final_datasets_normalized/\""],"metadata":{"id":"0WgEOQzDLk6i"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JWbs_6ppp5cB"},"outputs":[],"source":["class Arguments():\n","    def __init__(self):\n","        self.images = 60000\n","        self.clients = 2\n","        self.rounds = 5\n","        self.epochs = 5\n","        self.local_batches = 64\n","        self.lr = 0.01\n","        self.C = 0.9\n","        self.drop_rate = 0.1\n","        self.torch_seed = 0\n","        self.log_interval = 10\n","        self.iid = 'iid'\n","        self.split_size = int(self.images / self.clients)\n","        self.samples = self.split_size / self.images \n","        self.use_cuda = False\n","        self.save_model = False\n","\n","args = Arguments()\n","\n","use_cuda = args.use_cuda and th.cuda.is_available()\n","device = th.device(\"cuda\" if use_cuda else \"cpu\")\n","kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FR2f7bfVp5cC"},"outputs":[],"source":["def binary_acc(y_pred, y_test):\n","    y_pred_tag = th.round(th.sigmoid(y_pred))\n","\n","    correct_results_sum = (y_pred_tag == y_test).sum().float()\n","    acc = correct_results_sum/y_test.shape[0]\n","    acc = th.round(acc * 100)\n","    \n","    return acc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4d0tS7QPaCqW"},"outputs":[],"source":["# Load data and drop irrelevant columns\n","\n","alice_set = pd.read_csv(path + \"TRAINING_SET_1.csv\")\n","bob_set = pd.read_csv(path + \"TRAINING_SET_2.csv\")\n","\n","test_set = pd.read_csv(path + \"TEST_SET_FULL.csv\")\n","\n","drop_cols = [\"cycle\",\"setting3\",\"s1\",\"s5\",\"s10\",\"s16\",\"s18\",\"s19\",\"RUL\"]\n","corr_cols = [\"s11\",\"s4\",\"s15\",\"s17\",\"s2\",\"s3\",\"s8\",\"s13\",\"s9\",\"s14\",\"s12\",\"s7\",\"s20\"]\n","feature_cols = ['cycle_norm', 'setting1', 'setting2', 's2', 's3', 's4', 's6', 's7',\n","       's8', 's9', 's11', 's12', 's13', 's14', 's15', 's17', 's20', 's21']\n","prediction_col = 'fail_30'\n","\n","alice_set = alice_set.drop(drop_cols, axis=1)\n","bob_set = bob_set.drop(drop_cols, axis=1)\n","\n","test_set = test_set.drop(drop_cols, axis=1)"]},{"cell_type":"code","source":["# Receives single engine dataframe, window size and features -> sequences of length==window_size\n","def gen_train_data(df, sequence_length, columns):\n","    data = df[columns].values\n","    num_elements = data.shape[0]\n","\n","    # -1 and +1 because of Python indexing\n","    for start, stop in zip(range(0, num_elements-(sequence_length-1)), range(sequence_length, num_elements+1)):\n","        yield data[start:stop, :]"],"metadata":{"id":"4sgHO7msRYAH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Generates sequences for multiple engines\n","def gen_data_wrapper(df, sequence_length, columns, ids=np.array([])):\n","    if ids.size <= 0:\n","        ids = df['id'].unique()\n","        \n","    data_gen = (list(gen_train_data(df[df['id']==id], sequence_length, columns))\n","               for id in ids)\n","    data_array = np.concatenate(list(data_gen)).astype(np.float32)\n","    return data_array"],"metadata":{"id":"brWJ8eLKS1gx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Functions to generate sequences for the labals\n","def gen_labels(df, sequence_length, label):\n","    data_matrix = df[label].values\n","    num_elements = data_matrix.shape[0]\n","\n","    # -1 because I want to predict the rul of that last row in the sequence, not the next row\n","    return data_matrix[sequence_length-1:num_elements, :]  \n","\n","def gen_label_wrapper(df, sequence_length, label, ids=np.array([])):\n","    if ids.size <= 0:\n","        ids = df['id'].unique()\n","        \n","    label_gen = [gen_labels(df[df['id']==id], sequence_length, label) \n","                for id in ids]\n","    label_array = np.concatenate(label_gen).astype(np.float32)\n","    return label_array"],"metadata":{"id":"BfPw_1ylZPgP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def gen_test_data(df, sequence_length, columns, mask_value):\n","    if df.shape[0] < sequence_length:\n","        data_matrix = np.full(shape=(sequence_length, len(columns)), fill_value=mask_value) # pad\n","        idx = data_matrix.shape[0] - df.shape[0]\n","        data_matrix[idx:,:] = df[columns].values  # fill with available data\n","    else:\n","        data_matrix = df[columns].values\n","        \n","    # specifically yield the last possible sequence\n","    stop = num_elements = data_matrix.shape[0]\n","    start = stop - sequence_length\n","    for i in list(range(1)):\n","        yield data_matrix[start:stop, :]\n","def gen_test_label_wrapper(df, sequence_length, label, ids=np.array([])):\n","    if ids.size <= 0:\n","        ids = df['id'].unique()\n","    \n","    label_gen = [gen_labels(df[df['id']==id], sequence_length, label) \n","                for id in ids]\n","    # keep only last window\n","    if sequence_length > 31:\n","      print(\"Too big window\")\n","    else:\n","      last_labels = [label[-1] for label in label_gen] \n","      \n","\n","\n","\n","    last_labels = np.concatenate(last_labels).astype(np.float32)\n","    # return label_array\n","    return last_labels\n"],"metadata":{"id":"tTAYBQ9yOOFV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Functions to generate sequences for the labals\n","def gen_labels(df, sequence_length, label):\n","    data_matrix = df[label].values\n","    num_elements = data_matrix.shape[0]\n","\n","    # -1 because I want to predict the rul of that last row in the sequence, not the next row\n","    return data_matrix[sequence_length-1:num_elements, :]  \n","\n","def gen_label_wrapper(df, sequence_length, label, ids=np.array([])):\n","    if ids.size <= 0:\n","        ids = df['id'].unique()\n","        \n","    label_gen = [gen_labels(df[df['id']==id], sequence_length, label) \n","                for id in ids]\n","    label_array = np.concatenate(label_gen).astype(np.float32)\n","    return label_array"],"metadata":{"id":"KCmZsr6mtxw1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def gen_test_data(df, sequence_length, columns, mask_value):\n","    if df.shape[0] < sequence_length:\n","        data_matrix = np.full(shape=(sequence_length, len(columns)), fill_value=mask_value) # pad\n","        idx = data_matrix.shape[0] - df.shape[0]\n","        data_matrix[idx:,:] = df[columns].values  # fill with available data\n","    else:\n","        data_matrix = df[columns].values\n","        \n","    # specifically yield the last possible sequence\n","    stop = num_elements = data_matrix.shape[0]\n","    start = stop - sequence_length\n","    for i in list(range(1)):\n","        yield data_matrix[start:stop, :]\n","def gen_test_label_wrapper(df, sequence_length, label, ids=np.array([])):\n","    if ids.size <= 0:\n","        ids = df['id'].unique()\n","    \n","    label_gen = [gen_labels(df[df['id']==id], sequence_length, label) \n","                for id in ids]\n","    # keep only last window\n","    if sequence_length > 31:\n","      print(\"Too big window\")\n","    else:\n","      last_labels = [label[-1] for label in label_gen] \n","      \n","    last_labels = np.concatenate(last_labels).astype(np.float32)\n","    # return label_array\n","    return last_labels\n"],"metadata":{"id":"zlV9n_h_txw2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sequence_length = 20\n","\n","gss = GroupShuffleSplit(n_splits=1, train_size=0.80, random_state=42)\n","\n","\n","for alice_train_unit, alice_val_unit in gss.split(alice_set['id'].unique(), groups=alice_set['id'].unique()):\n","    alice_train_unit = alice_set['id'].unique()[alice_train_unit]  # gss returns indexes and index starts at 1\n","    alice_val_unit = alice_set['id'].unique()[alice_val_unit]\n","\n","    train_split_array = gen_data_wrapper(alice_set, sequence_length, feature_cols, alice_train_unit)\n","    train_split_label = gen_label_wrapper(alice_set, sequence_length, ['fail_30'], alice_train_unit)\n","    \n","    val_split_array = gen_data_wrapper(alice_set, sequence_length, feature_cols, alice_val_unit)\n","    val_split_label = gen_label_wrapper(alice_set, sequence_length, ['fail_30'], alice_val_unit)\n","\n","for bob_train_unit, bob_val_unit in gss.split(bob_set['id'].unique(), groups=bob_set['id'].unique()):\n","    bob_train_unit = bob_set['id'].unique()[bob_train_unit]  # gss returns indexes and index starts at 1\n","    bob_val_unit = bob_set['id'].unique()[bob_val_unit]\n","\n","    train_split_array = gen_data_wrapper(bob_set, sequence_length, feature_cols, bob_train_unit)\n","    train_split_label = gen_label_wrapper(bob_set, sequence_length, ['fail_30'], bob_train_unit)\n","    \n","    val_split_array = gen_data_wrapper(bob_set, sequence_length, feature_cols, bob_val_unit)\n","    val_split_label = gen_label_wrapper(bob_set, sequence_length, ['fail_30'], bob_val_unit)\n","\n","# create sequences train, test \n","X_alice = gen_data_wrapper(alice_set, sequence_length, feature_cols)\n","X_bob = gen_data_wrapper(bob_set, sequence_length, feature_cols)\n","\n","y_alice = gen_label_wrapper(alice_set, sequence_length, ['fail_30'])\n","y_bob = gen_label_wrapper(bob_set, sequence_length, ['fail_30'])\n","\n","\n","test_gen = (list(gen_test_data(test_set[test_set['id']==id], sequence_length, feature_cols, -99.))\n","           for id in test_set['id'].unique())\n","X_test = np.concatenate(list(test_gen)).astype(np.float32)\n","\n","y_test = gen_test_label_wrapper(test_set, sequence_length, ['fail_30'])\n"],"metadata":{"id":"eOqZ7XIYFoRV"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YhFVM5aCQWQn"},"outputs":[],"source":["# Defining custom dataset class for convenience\n","\n","class CustomDataset(Dataset):\n","    \n","    def __init__(self, X_data, y_data):\n","        self.X_data = X_data\n","        self.y_data = y_data\n","        \n","    def __getitem__(self, index):\n","        return self.X_data[index], self.y_data[index]\n","        \n","    def __len__ (self):\n","        return len(self.X_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cgm_5Y0HaCxM"},"outputs":[],"source":["alice_dataset = CustomDataset(X_alice, y_alice)\n","bob_dataset = CustomDataset(X_bob, y_bob)\n","test_dataset = CustomDataset(X_test, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TPryp_7LRRiX"},"outputs":[],"source":["alice_loader = DataLoader(dataset=alice_dataset, batch_size=args.local_batches, shuffle=False)\n","bob_loader = DataLoader(dataset=bob_dataset, batch_size=args.local_batches, shuffle=False)\n","test_loader = DataLoader(dataset=test_dataset, batch_size=args.local_batches, shuffle=False)"]},{"cell_type":"code","source":["clients[0]['trainset'] = alice_loader\n","clients[1]['trainset'] = bob_loader\n"],"metadata":{"id":"hUAYLs28PWJz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class BinaryClassification(sy.Module):\n","    def __init__(self, torch_ref):\n","        super(BinaryClassification, self).__init__(torch_ref=torch_ref)\n","        self.num_features = 18\n","        self.hidden_units = 32\n","        self.num_layers = 1\n","\n","        self.lstm = nn.LSTM(\n","            input_size=self.num_features,\n","            hidden_size=self.hidden_units,\n","            batch_first=True,\n","            num_layers=self.num_layers) \n","        \n","        self.linear = nn.Linear(in_features=self.hidden_units, out_features=1)\n","\n","    def forward(self, x):\n","      batch_size = x.shape[0]\n","      h0 = th.zeros(self.num_layers, batch_size, self.hidden_units).requires_grad_()\n","      c0 = th.zeros(self.num_layers, batch_size, self.hidden_units).requires_grad_()\n","      _, (hn, _) = self.lstm(x, (h0, c0))\n","      out = self.linear(hn[0]).flatten()  # First dim of Hn is num_layers, which is set to 1 above.\n","\n","      return out"],"metadata":{"id":"eujaS32aPWP1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["EPOCHS = 5\n","LEARNING_RATE = 0.001\n","criterion = nn.BCEWithLogitsLoss()"],"metadata":{"id":"e8Lf7B5sObKF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# diko tous torch oi client"],"metadata":{"id":"TizSq_Y8Sov-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["clients"],"metadata":{"id":"HtqG5yKgVNxF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["th.manual_seed(args.torch_seed)\n","global_model = BinaryClassification(th)\n","\n","\n","for client in clients:\n","    th.manual_seed(args.torch_seed)\n","    client['model'] = BinaryClassification(client['torch'])\n","\n","    client['optim'] = None\n","\n","# clients[0]\n","# clients[0]['optim'] = optim.SGD(clients[0]['model'].parameters(), lr=args.lr)\n","\n","# clients[0]['model'].send(clients[0]['hook'])\n","\n"],"metadata":{"id":"9IsqmTWrPWYC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print(model.parameters()[-1].grad) # exists\n","\n","# model_ptr = model.send(alice_client)\n","# data_ptr = data.send(alice_client)\n","# labels_ptr = labels.send(alice_client)\n","# results_ptr = model_ptr(data_ptr)\n","# remote_loss_func = alice_client.torch.nn.L1Loss()\n","# remote_loss = remote_loss_func(results_ptr, labels_ptr)\n","# remote_loss.backward()"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1631170072306},"id":"geSNoqTTefdj"}},{"cell_type":"code","source":["# input = X_train[0].view(1,20,18)\n","\n","\n"],"metadata":{"id":"rN4C7QOBxLOM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input = X_train[18667:]\n","output = y_train[18667:]\n","input_ptr = input.send(alice_client)\n","output_ptr = output.send(alice_client)"],"metadata":{"id":"yQhLLPZHHTXV","colab":{"base_uri":"https://localhost:8080/","height":226},"executionInfo":{"status":"error","timestamp":1644509150922,"user_tz":-120,"elapsed":11,"user":{"displayName":"return 0;","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN3tMOj_-g1ogwXC98E7gl1-D32a9_FPyIXLw0=s64","userId":"06352786353642446060"}},"outputId":"361fe916-f1fc-41d6-ea63-9f1c717fd263"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-52d82401d198>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m18667\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m18667\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minput_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malice_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moutput_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malice_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"]}]},{"cell_type":"code","source":["result_ptr.shape.get()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gFJTQM4qMPwb","executionInfo":{"status":"ok","timestamp":1644438823531,"user_tz":-120,"elapsed":256,"user":{"displayName":"return 0;","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN3tMOj_-g1ogwXC98E7gl1-D32a9_FPyIXLw0=s64","userId":"06352786353642446060"}},"outputId":"2acf5a95-32c7-440f-b72e-8f6f4cd4b61d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([64])"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["output_ptr.view(-1).shape.get()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YmfLbyk_MTxc","executionInfo":{"status":"ok","timestamp":1644438864637,"user_tz":-120,"elapsed":282,"user":{"displayName":"return 0;","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN3tMOj_-g1ogwXC98E7gl1-D32a9_FPyIXLw0=s64","userId":"06352786353642446060"}},"outputId":"bd2d669e-796e-438f-aedc-464855b81ca6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([64])"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":[""],"metadata":{"id":"8J74aC5U8ArL"},"execution_count":null,"outputs":[]}]}