{"cells":[{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":262,"status":"ok","timestamp":1643664791013,"user":{"displayName":"return 0;","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN3tMOj_-g1ogwXC98E7gl1-D32a9_FPyIXLw0=s64","userId":"06352786353642446060"},"user_tz":-120},"id":"wlW2f3FIMIPF"},"outputs":[],"source":["# !pip install syft==0.2.9"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1643664791364,"user":{"displayName":"return 0;","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN3tMOj_-g1ogwXC98E7gl1-D32a9_FPyIXLw0=s64","userId":"06352786353642446060"},"user_tz":-120},"id":"GPitAKie9oM3"},"outputs":[],"source":["import torch as th\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader, Dataset\n","import syft as sy\n","import copy\n","import numpy as np\n","import pandas as pd\n","import time\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import GroupShuffleSplit"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1643664791365,"user":{"displayName":"return 0;","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN3tMOj_-g1ogwXC98E7gl1-D32a9_FPyIXLw0=s64","userId":"06352786353642446060"},"user_tz":-120},"id":"hcrtFKxtL_Rs"},"outputs":[],"source":["class Arguments():\n","    def __init__(self):\n","        self.images = 60000\n","        self.clients = 2\n","        self.rounds = 1\n","        self.epochs = 5\n","        self.local_batches = 64\n","        self.lr = 0.01\n","        self.C = 0.9\n","        self.drop_rate = 0.1\n","        self.torch_seed = 0\n","        self.log_interval = 10\n","        self.iid = 'iid'\n","        self.split_size = int(self.images / self.clients)\n","        self.samples = self.split_size / self.images \n","        self.use_cuda = False\n","        self.save_model = False\n","\n","args = Arguments()\n","\n","use_cuda = args.use_cuda and th.cuda.is_available()\n","device = th.device(\"cuda\" if use_cuda else \"cpu\")\n","kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1643664791365,"user":{"displayName":"return 0;","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN3tMOj_-g1ogwXC98E7gl1-D32a9_FPyIXLw0=s64","userId":"06352786353642446060"},"user_tz":-120},"id":"11ba98c0","outputId":"43282424-1ccc-4046-ca74-ad5dcb46b687"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:root:Torch was already hooked... skipping hooking process\n"]}],"source":["hook = sy.TorchHook(th)\n","clients = []\n","\n","for i in range(args.clients):\n","    clients.append({'hook': sy.VirtualWorker(hook, id=\"client{}\".format(i+1))})"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1643664791366,"user":{"displayName":"return 0;","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN3tMOj_-g1ogwXC98E7gl1-D32a9_FPyIXLw0=s64","userId":"06352786353642446060"},"user_tz":-120},"id":"qkfCxEUeMU-v"},"outputs":[],"source":["path = \"/content/drive/MyDrive/Thesis/Datasets/Turbofan_Dataset/final_datasets_normalized/\""]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1643664791367,"user":{"displayName":"return 0;","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN3tMOj_-g1ogwXC98E7gl1-D32a9_FPyIXLw0=s64","userId":"06352786353642446060"},"user_tz":-120},"id":"JWbs_6ppp5cB"},"outputs":[],"source":["class Arguments():\n","    def __init__(self):\n","        self.images = 60000\n","        self.clients = 2\n","        self.rounds = 5\n","        self.epochs = 5\n","        self.local_batches = 64\n","        self.lr = 0.01\n","        self.C = 0.9\n","        self.drop_rate = 0.1\n","        self.torch_seed = 0\n","        self.log_interval = 10\n","        self.iid = 'iid'\n","        self.split_size = int(self.images / self.clients)\n","        self.samples = self.split_size / self.images \n","        self.use_cuda = False\n","        self.save_model = False\n","\n","args = Arguments()\n","\n","use_cuda = args.use_cuda and th.cuda.is_available()\n","device = th.device(\"cuda\" if use_cuda else \"cpu\")\n","kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":371,"status":"ok","timestamp":1643664791728,"user":{"displayName":"return 0;","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN3tMOj_-g1ogwXC98E7gl1-D32a9_FPyIXLw0=s64","userId":"06352786353642446060"},"user_tz":-120},"id":"FR2f7bfVp5cC"},"outputs":[],"source":["def binary_acc(y_pred, y_test):\n","    y_pred_tag = th.round(th.sigmoid(y_pred))\n","\n","    correct_results_sum = (y_pred_tag == y_test).sum().float()\n","    acc = correct_results_sum/y_test.shape[0]\n","    acc = th.round(acc * 100)\n","    \n","    return acc"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1643664791729,"user":{"displayName":"return 0;","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN3tMOj_-g1ogwXC98E7gl1-D32a9_FPyIXLw0=s64","userId":"06352786353642446060"},"user_tz":-120},"id":"uu0RjBNgp5cD","outputId":"05eee0e5-7546-4426-ae5b-a3cda42019e2"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:root:Torch was already hooked... skipping hooking process\n"]}],"source":["hook = sy.TorchHook(th)\n","clients = []\n","\n","for i in range(args.clients):\n","    clients.append({'hook': sy.VirtualWorker(hook, id=\"client{}\".format(i+1))})"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":1730,"status":"ok","timestamp":1643664793450,"user":{"displayName":"return 0;","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN3tMOj_-g1ogwXC98E7gl1-D32a9_FPyIXLw0=s64","userId":"06352786353642446060"},"user_tz":-120},"id":"4d0tS7QPaCqW"},"outputs":[],"source":["# Load data and drop irrelevant columns\n","\n","alice_set = pd.read_csv(path + \"TRAINING_SET_1.csv\")\n","bob_set = pd.read_csv(path + \"TRAINING_SET_2.csv\")\n","\n","test_set = pd.read_csv(path + \"TEST_SET_FULL.csv\")\n","\n","drop_cols = [\"cycle\",\"setting3\",\"s1\",\"s5\",\"s10\",\"s16\",\"s18\",\"s19\",\"RUL\"]\n","corr_cols = [\"s11\",\"s4\",\"s15\",\"s17\",\"s2\",\"s3\",\"s8\",\"s13\",\"s9\",\"s14\",\"s12\",\"s7\",\"s20\"]\n","feature_cols = ['cycle_norm', 'setting1', 'setting2', 's2', 's3', 's4', 's6', 's7',\n","       's8', 's9', 's11', 's12', 's13', 's14', 's15', 's17', 's20', 's21']\n","prediction_col = 'fail_30'\n","\n","alice_set = alice_set.drop(drop_cols, axis=1)\n","bob_set = bob_set.drop(drop_cols, axis=1)\n","\n","test_set = test_set.drop(drop_cols, axis=1)"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1643664793452,"user":{"displayName":"return 0;","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN3tMOj_-g1ogwXC98E7gl1-D32a9_FPyIXLw0=s64","userId":"06352786353642446060"},"user_tz":-120},"id":"4sgHO7msRYAH"},"outputs":[],"source":["# Receives single engine dataframe, window size and features -\u003e sequences of length==window_size\n","def gen_train_data(df, sequence_length, columns):\n","    data = df[columns].values\n","    num_elements = data.shape[0]\n","\n","    # -1 and +1 because of Python indexing\n","    for start, stop in zip(range(0, num_elements-(sequence_length-1)), range(sequence_length, num_elements+1)):\n","        yield data[start:stop, :]"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1643664793454,"user":{"displayName":"return 0;","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN3tMOj_-g1ogwXC98E7gl1-D32a9_FPyIXLw0=s64","userId":"06352786353642446060"},"user_tz":-120},"id":"brWJ8eLKS1gx"},"outputs":[],"source":["# Generates sequences for multiple engines\n","def gen_data_wrapper(df, sequence_length, columns, ids=np.array([])):\n","    if ids.size \u003c= 0:\n","        ids = df['id'].unique()\n","        \n","    data_gen = (list(gen_train_data(df[df['id']==id], sequence_length, columns))\n","               for id in ids)\n","    data_array = np.concatenate(list(data_gen)).astype(np.float32)\n","    return data_array"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1643664793455,"user":{"displayName":"return 0;","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN3tMOj_-g1ogwXC98E7gl1-D32a9_FPyIXLw0=s64","userId":"06352786353642446060"},"user_tz":-120},"id":"BfPw_1ylZPgP"},"outputs":[],"source":["# Functions to generate sequences for the labals\n","def gen_labels(df, sequence_length, label):\n","    data_matrix = df[label].values\n","    num_elements = data_matrix.shape[0]\n","\n","    # -1 because I want to predict the rul of that last row in the sequence, not the next row\n","    return data_matrix[sequence_length-1:num_elements, :]  \n","\n","def gen_label_wrapper(df, sequence_length, label, ids=np.array([])):\n","    if ids.size \u003c= 0:\n","        ids = df['id'].unique()\n","        \n","    label_gen = [gen_labels(df[df['id']==id], sequence_length, label) \n","                for id in ids]\n","    label_array = np.concatenate(label_gen).astype(np.float32)\n","    return label_array"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1643664793456,"user":{"displayName":"return 0;","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN3tMOj_-g1ogwXC98E7gl1-D32a9_FPyIXLw0=s64","userId":"06352786353642446060"},"user_tz":-120},"id":"tTAYBQ9yOOFV"},"outputs":[],"source":["def gen_test_data(df, sequence_length, columns, mask_value):\n","    if df.shape[0] \u003c sequence_length:\n","        data_matrix = np.full(shape=(sequence_length, len(columns)), fill_value=mask_value) # pad\n","        idx = data_matrix.shape[0] - df.shape[0]\n","        data_matrix[idx:,:] = df[columns].values  # fill with available data\n","    else:\n","        data_matrix = df[columns].values\n","        \n","    # specifically yield the last possible sequence\n","    stop = num_elements = data_matrix.shape[0]\n","    start = stop - sequence_length\n","    for i in list(range(1)):\n","        yield data_matrix[start:stop, :]\n","def gen_test_label_wrapper(df, sequence_length, label, ids=np.array([])):\n","    if ids.size \u003c= 0:\n","        ids = df['id'].unique()\n","    \n","    label_gen = [gen_labels(df[df['id']==id], sequence_length, label) \n","                for id in ids]\n","    # keep only last window\n","    if sequence_length \u003e 31:\n","      print(\"Too big window\")\n","    else:\n","      last_labels = [label[-1] for label in label_gen] \n","      \n","\n","\n","\n","    last_labels = np.concatenate(last_labels).astype(np.float32)\n","    # return label_array\n","    return last_labels\n"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1643664793457,"user":{"displayName":"return 0;","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN3tMOj_-g1ogwXC98E7gl1-D32a9_FPyIXLw0=s64","userId":"06352786353642446060"},"user_tz":-120},"id":"KCmZsr6mtxw1"},"outputs":[],"source":["# Functions to generate sequences for the labals\n","def gen_labels(df, sequence_length, label):\n","    data_matrix = df[label].values\n","    num_elements = data_matrix.shape[0]\n","\n","    # -1 because I want to predict the rul of that last row in the sequence, not the next row\n","    return data_matrix[sequence_length-1:num_elements, :]  \n","\n","def gen_label_wrapper(df, sequence_length, label, ids=np.array([])):\n","    if ids.size \u003c= 0:\n","        ids = df['id'].unique()\n","        \n","    label_gen = [gen_labels(df[df['id']==id], sequence_length, label) \n","                for id in ids]\n","    label_array = np.concatenate(label_gen).astype(np.float32)\n","    return label_array"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1643664793458,"user":{"displayName":"return 0;","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN3tMOj_-g1ogwXC98E7gl1-D32a9_FPyIXLw0=s64","userId":"06352786353642446060"},"user_tz":-120},"id":"zlV9n_h_txw2"},"outputs":[],"source":["def gen_test_data(df, sequence_length, columns, mask_value):\n","    if df.shape[0] \u003c sequence_length:\n","        data_matrix = np.full(shape=(sequence_length, len(columns)), fill_value=mask_value) # pad\n","        idx = data_matrix.shape[0] - df.shape[0]\n","        data_matrix[idx:,:] = df[columns].values  # fill with available data\n","    else:\n","        data_matrix = df[columns].values\n","        \n","    # specifically yield the last possible sequence\n","    stop = num_elements = data_matrix.shape[0]\n","    start = stop - sequence_length\n","    for i in list(range(1)):\n","        yield data_matrix[start:stop, :]\n","def gen_test_label_wrapper(df, sequence_length, label, ids=np.array([])):\n","    if ids.size \u003c= 0:\n","        ids = df['id'].unique()\n","    \n","    label_gen = [gen_labels(df[df['id']==id], sequence_length, label) \n","                for id in ids]\n","    # keep only last window\n","    if sequence_length \u003e 31:\n","      print(\"Too big window\")\n","    else:\n","      last_labels = [label[-1] for label in label_gen] \n","      \n","    last_labels = np.concatenate(last_labels).astype(np.float32)\n","    # return label_array\n","    return last_labels\n"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":1240,"status":"ok","timestamp":1643664795016,"user":{"displayName":"return 0;","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN3tMOj_-g1ogwXC98E7gl1-D32a9_FPyIXLw0=s64","userId":"06352786353642446060"},"user_tz":-120},"id":"eOqZ7XIYFoRV"},"outputs":[],"source":["sequence_length = 20\n","\n","gss = GroupShuffleSplit(n_splits=1, train_size=0.80, random_state=42)\n","\n","\n","for alice_train_unit, alice_val_unit in gss.split(alice_set['id'].unique(), groups=alice_set['id'].unique()):\n","    alice_train_unit = alice_set['id'].unique()[alice_train_unit]  # gss returns indexes and index starts at 1\n","    alice_val_unit = alice_set['id'].unique()[alice_val_unit]\n","\n","    train_split_array = gen_data_wrapper(alice_set, sequence_length, feature_cols, alice_train_unit)\n","    train_split_label = gen_label_wrapper(alice_set, sequence_length, ['fail_30'], alice_train_unit)\n","    \n","    val_split_array = gen_data_wrapper(alice_set, sequence_length, feature_cols, alice_val_unit)\n","    val_split_label = gen_label_wrapper(alice_set, sequence_length, ['fail_30'], alice_val_unit)\n","\n","for bob_train_unit, bob_val_unit in gss.split(bob_set['id'].unique(), groups=bob_set['id'].unique()):\n","    bob_train_unit = bob_set['id'].unique()[bob_train_unit]  # gss returns indexes and index starts at 1\n","    bob_val_unit = bob_set['id'].unique()[bob_val_unit]\n","\n","    train_split_array = gen_data_wrapper(bob_set, sequence_length, feature_cols, bob_train_unit)\n","    train_split_label = gen_label_wrapper(bob_set, sequence_length, ['fail_30'], bob_train_unit)\n","    \n","    val_split_array = gen_data_wrapper(bob_set, sequence_length, feature_cols, bob_val_unit)\n","    val_split_label = gen_label_wrapper(bob_set, sequence_length, ['fail_30'], bob_val_unit)\n","\n","# create sequences train, test \n","X_alice = gen_data_wrapper(alice_set, sequence_length, feature_cols)\n","X_bob = gen_data_wrapper(bob_set, sequence_length, feature_cols)\n","\n","y_alice = gen_label_wrapper(alice_set, sequence_length, ['fail_30'])\n","y_bob = gen_label_wrapper(bob_set, sequence_length, ['fail_30'])\n","\n","\n","test_gen = (list(gen_test_data(test_set[test_set['id']==id], sequence_length, feature_cols, -99.))\n","           for id in test_set['id'].unique())\n","X_test = np.concatenate(list(test_gen)).astype(np.float32)\n","\n","y_test = gen_test_label_wrapper(test_set, sequence_length, ['fail_30'])\n"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1643664795018,"user":{"displayName":"return 0;","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN3tMOj_-g1ogwXC98E7gl1-D32a9_FPyIXLw0=s64","userId":"06352786353642446060"},"user_tz":-120},"id":"YhFVM5aCQWQn"},"outputs":[],"source":["# Defining custom dataset class for convenience\n","\n","class CustomDataset(Dataset):\n","    \n","    def __init__(self, X_data, y_data):\n","        self.X_data = X_data\n","        self.y_data = y_data\n","        \n","    def __getitem__(self, index):\n","        return self.X_data[index], self.y_data[index]\n","        \n","    def __len__ (self):\n","        return len(self.X_data)"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1643664795019,"user":{"displayName":"return 0;","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN3tMOj_-g1ogwXC98E7gl1-D32a9_FPyIXLw0=s64","userId":"06352786353642446060"},"user_tz":-120},"id":"Cgm_5Y0HaCxM"},"outputs":[],"source":["alice_dataset = CustomDataset(X_alice, y_alice)\n","bob_dataset = CustomDataset(X_bob, y_bob)\n","test_dataset = CustomDataset(X_test, y_test)"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1643664795021,"user":{"displayName":"return 0;","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN3tMOj_-g1ogwXC98E7gl1-D32a9_FPyIXLw0=s64","userId":"06352786353642446060"},"user_tz":-120},"id":"TPryp_7LRRiX"},"outputs":[],"source":["alice_loader = DataLoader(dataset=alice_dataset, batch_size=args.local_batches, shuffle=False)\n","bob_loader = DataLoader(dataset=bob_dataset, batch_size=args.local_batches, shuffle=False)\n","test_loader = DataLoader(dataset=test_dataset, batch_size=args.local_batches, shuffle=False)"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1643664795022,"user":{"displayName":"return 0;","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN3tMOj_-g1ogwXC98E7gl1-D32a9_FPyIXLw0=s64","userId":"06352786353642446060"},"user_tz":-120},"id":"WVFJZpLDPtDM"},"outputs":[],"source":["clients[0]['trainset'] = alice_loader\n","clients[1]['trainset'] = bob_loader"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1643664795023,"user":{"displayName":"return 0;","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN3tMOj_-g1ogwXC98E7gl1-D32a9_FPyIXLw0=s64","userId":"06352786353642446060"},"user_tz":-120},"id":"ejWud_ptEcVq"},"outputs":[],"source":["class BinaryClassification(nn.Module):\n","    def __init__(self):\n","        super(BinaryClassification, self).__init__()\n","        self.num_features = 18\n","        self.hidden_units = 32\n","        self.num_layers = 1\n","\n","        self.rnn = nn.RNN(\n","            input_size=self.num_features,\n","            hidden_size=self.hidden_units,\n","            batch_first=True,\n","            num_layers=self.num_layers) \n","        \n","        self.linear = nn.Linear(in_features=self.hidden_units, out_features=1)\n","\n","        self.tanh = nn.Tanh()\n","        # self.sigmoid = nn.Sigmoid()\n","        \n","    def forward(self, x):\n","      batch_size = x.shape[0]\n","      h0 = torch.zeros(self.num_layers, batch_size, self.hidden_units).requires_grad_()\n","      # c0 = torch.zeros(self.num_layers, batch_size, self.hidden_units).requires_grad_()\n","      _, hn = self.rnn(x, h0)\n","      out = self.linear(hn[0]).flatten()  # First dim of Hn is num_layers, which is set to 1 above.\n","\n","      return out\n","        # x, (hn, cn) = self.lstm1(inputs)\n","        # x = self.linear(x)\n","        # x = self.tanh(x) \n","        # return x"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"n-W9UgGkAvBH"},"outputs":[{"ename":"MessageError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-32-d5df0069828e\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    111\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m       \u001b[0muse_metadata_server\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_metadata_server\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 113\u001b[0;31m       ephemeral=ephemeral)\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server, ephemeral)\u001b[0m\n\u001b[1;32m    134\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     _message.blocking_request(\n\u001b[0;32m--\u003e 136\u001b[0;31m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mmountpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    173\u001b[0m   request_id = send_request(\n\u001b[1;32m    174\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--\u003e 175\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P1KO5MfgOnr1"},"outputs":[],"source":["device = th.device(\"cuda:0\" if th.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"e8Lf7B5sObKF"},"outputs":[],"source":["EPOCHS = 5\n","LEARNING_RATE = 0.001\n","criterion = nn.BCEWithLogitsLoss()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"bZKRBacvmKr2"},"outputs":[],"source":["th.manual_seed(args.torch_seed)\n","global_model = BinaryClassification()\n","\n","for client in clients:\n","    th.manual_seed(args.torch_seed)\n","    client['model'] = BinaryClassification().to(device)\n","    client['optim'] = optim.SGD(client['model'].parameters(), lr=args.lr)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"nmFmHuU6O6hx"},"outputs":[],"source":["def binary_acc(y_pred, y_test):\n","    y_pred_tag = th.round(th.sigmoid(y_pred))\n","\n","    correct_results_sum = (y_pred_tag == y_test).sum().float()\n","    acc = correct_results_sum/y_test.shape[0]\n","    acc = th.round(acc * 100)\n","    \n","    return acc"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"mWN6WlcKUgsR"},"outputs":[],"source":["def ClientUpdate(args, device, client):\n","    client['model'].train()\n","    client['model'].send(client['hook'])\n","\n","    for epoch in range(1, args.epochs + 1):\n","\n","        for batch_idx, (data, target) in enumerate(client['trainset']):\n","            data = data.send(client['hook'])\n","            target = target.send(client['hook'])\n","            \n","            data, target = data.to(device), target.to(device)\n","            client['optim'].zero_grad()\n","            print(\"before\")\n","            print(data.size(0))\n","            output = client['model'](data)\n","            loss = criterion(output, target.unsqueeze(1))\n","            acc = binary_acc(target, target.unsqueeze(1))\n","            loss.backward()\n","            client['optim'].step()\n","\n","\n","            \n","            # if batch_idx % args.log_interval == 0:\n","            #     loss = loss.get()\n","            #     acc = acc.get() \n","                # print('Model {} Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                #     client['hook'].id,\n","                #     epoch, batch_idx * args.local_batches, len(client['trainset']) * args.local_batches, \n","                #     100. * batch_idx / len(client['trainset']), loss))\n","        # print(f'Epoch {epoch+0:03}: | Loss: {epoch_loss/len(client[\"trainset\"]):.5f} | Acc: {epoch_acc/(args.local_batches * len(client[\"trainset\"])):.3f}')\n","                \n","    client['model'].get() \n","\n","def averageModels(global_model, clients):\n","    client_models = [clients[i]['model'] for i in range(len(clients))]\n","    # samples = [clients[i]['samples'] for i in range(len(clients))]\n","    global_dict = global_model.state_dict()\n","    \n","    for k in global_dict.keys():\n","        global_dict[k] = th.stack([client_models[i].state_dict()[k].float() * 0.5 for i in range(len(client_models))], 0).sum(0)\n","        # global_dict[k] = th.stack([client_models[i].state_dict()[k].float() * samples[i] for i in range(len(client_models))], 0).sum(0)\n","        \n","\n","    global_model.load_state_dict(global_dict)\n","\n","    # for i in range(len(client_models)):\n","    #   print(f\"model {i+1}\")\n","    #   print(client_models[i].state_dict())\n","    # print(\"global model\")\n","    # print(global_model.state_dict())\n","    return global_model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"izh6lZw6VIGP"},"outputs":[],"source":["for fed_round in range(args.rounds):\n","    \n","#     uncomment if you want a randome fraction for C every round\n","#     args.C = float(format(np.random.random(), '.1f'))\n","    \n","    print(f\"Federated round {fed_round+1}\")\n","    active_clients = clients\n","    \n","    # Training \n","    for client in active_clients:\n","        ClientUpdate(args, device, client)\n","    \n","#     # Testing \n","#     for client in active_clients:\n","#         test(args, client['model'], device, client['testset'], client['hook'].id)\n","    \n","    # Averaging \n","    global_model = averageModels(global_model, active_clients)\n","    \n","    # Testing the average model\n","    # test(args, global_model, device, global_test_loader, 'Global')\n","            \n","    # Share the global model with the clients\n","    for client in clients:\n","        client['model'].load_state_dict(global_model.state_dict())\n","        \n","# if (args.save_model):\n","#     torch.save(global_model.state_dict(), \"FedAvg.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"K0gNYYJ8TXOP"},"outputs":[],"source":["th.manual_seed(args.torch_seed)\n","global_model = BinaryClassification()\n","\n","for client in clients:\n","    th.manual_seed(args.torch_seed)\n","    client['model'] = BinaryClassification().to(device)\n","    client['optim'] = optim.SGD(client['model'].parameters(), lr=args.lr)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"KFqwgvsxWI--"},"outputs":[],"source":["for fed_round in range(args.rounds):\n","    \n","#     uncomment if you want a randome fraction for C every round\n","#     args.C = float(format(np.random.random(), '.1f'))\n","    \n","    print(f\"Federated round {fed_round+1}\")\n","    active_clients = clients\n","    \n","    # Training \n","    for client in active_clients:\n","        ClientUpdate(args, device, client)\n","    \n","#     # Testing \n","#     for client in active_clients:\n","#         test(args, client['model'], device, client['testset'], client['hook'].id)\n","    \n","    # Averaging \n","    global_model = averageModels(global_model, active_clients)\n","    \n","    # Testing the average model\n","    # test(args, global_model, device, global_test_loader, 'Global')\n","            \n","    # Share the global model with the clients\n","    for client in clients:\n","        client['model'].load_state_dict(global_model.state_dict())\n","        \n","# if (args.save_model):\n","#     torch.save(global_model.state_dict(), \"FedAvg.pt\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMgk2939R3eKrqDG2gvSgG3","mount_file_id":"1yzxIT7Fd7D744fh78KgOc8jp9JKY0lh8","name":"rnn pytorch FedAvg.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}