{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lstm pytorch centralized.ipynb","provenance":[],"mount_file_id":"1_G5GAPxXvuA-sFzWPEiROTrjja2QPdSh","authorship_tag":"ABX9TyPgghhjt+C2+kHLuJ9Vm0CP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Ac9TzbFuFjct"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","from sklearn.model_selection import GroupShuffleSplit\n","from sklearn.metrics import confusion_matrix, classification_report\n","\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader"]},{"cell_type":"code","source":["BATCH_SIZE = 64"],"metadata":{"id":"Z-y-jREbBVvW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path = \"/content/drive/MyDrive/Thesis/Datasets/Turbofan_Dataset/final_datasets_normalized/\""],"metadata":{"id":"4sTRT817Fn63"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load data and drop irrelevant columns\n","\n","df_train = pd.read_csv(path + \"TRAINING_SET_FULL.csv\")\n","df_test = pd.read_csv(path + \"TEST_SET_FULL.csv\")\n","\n","drop_cols = [\"cycle\",\"setting3\",\"s1\",\"s5\",\"s10\",\"s16\",\"s18\",\"s19\",\"RUL\"]\n","corr_cols = [\"s11\",\"s4\",\"s15\",\"s17\",\"s2\",\"s3\",\"s8\",\"s13\",\"s9\",\"s14\",\"s12\",\"s7\",\"s20\"]\n","feature_cols = ['cycle_norm', 'setting1', 'setting2', 's2', 's3', 's4', 's6', 's7',\n","       's8', 's9', 's11', 's12', 's13', 's14', 's15', 's17', 's20', 's21']\n","prediction_col = 'fail_30'\n","\n","train_set = df_train.drop(drop_cols, axis=1)\n","test_set = df_test.drop(drop_cols, axis=1)"],"metadata":{"id":"UzdFlyg5Fp_M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Move cycle_norm column first for convenience\n","\n","# column_to_move = train_set.pop(\"cycle_norm\")\n","# train_set.insert(0, \"cycle_norm\", column_to_move)\n","\n","# column_to_move = test_set.pop(\"cycle_norm\")\n","# test_set.insert(0, \"cycle_norm\", column_to_move)"],"metadata":{"id":"wxhshSB7KqNN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Receives single engine dataframe, window size and features -> sequences of length==window_size\n","def gen_train_data(df, sequence_length, columns):\n","    data = df[columns].values\n","    num_elements = data.shape[0]\n","\n","    # -1 and +1 because of Python indexing\n","    for start, stop in zip(range(0, num_elements-(sequence_length-1)), range(sequence_length, num_elements+1)):\n","        yield data[start:stop, :]"],"metadata":{"id":"4sgHO7msRYAH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# gen = gen_train_data(train_set[train_set['id']==1], sequence_length=4, columns=feature_cols)\n","# engines = list(gen)"],"metadata":{"id":"nvQiWUyOR6zZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Generates sequences for multiple engines\n","def gen_data_wrapper(df, sequence_length, columns, ids=np.array([])):\n","    if ids.size <= 0:\n","        ids = df['id'].unique()\n","        \n","    data_gen = (list(gen_train_data(df[df['id']==id], sequence_length, columns))\n","               for id in ids)\n","    data_array = np.concatenate(list(data_gen)).astype(np.float32)\n","    return data_array"],"metadata":{"id":"brWJ8eLKS1gx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_array = gen_data_wrapper(train_set, sequence_length=4, columns=feature_cols)\n","data_array.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UdTSZ_SOUNCx","executionInfo":{"status":"ok","timestamp":1643402708882,"user_tz":-120,"elapsed":22,"user":{"displayName":"return 0;","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN3tMOj_-g1ogwXC98E7gl1-D32a9_FPyIXLw0=s64","userId":"06352786353642446060"}},"outputId":"00f41b04-cdbb-458c-8f86-a51f55bd7153"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(20331, 4, 18)"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["# Functions to generate sequences for the labals\n","def gen_labels(df, sequence_length, label):\n","    data_matrix = df[label].values\n","    num_elements = data_matrix.shape[0]\n","\n","    # -1 because I want to predict the rul of that last row in the sequence, not the next row\n","    return data_matrix[sequence_length-1:num_elements, :]  \n","\n","def gen_label_wrapper(df, sequence_length, label, ids=np.array([])):\n","    if ids.size <= 0:\n","        ids = df['id'].unique()\n","        \n","    label_gen = [gen_labels(df[df['id']==id], sequence_length, label) \n","                for id in ids]\n","    label_array = np.concatenate(label_gen).astype(np.float32)\n","    return label_array"],"metadata":{"id":"BfPw_1ylZPgP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def gen_test_data(df, sequence_length, columns, mask_value):\n","    if df.shape[0] < sequence_length:\n","        data_matrix = np.full(shape=(sequence_length, len(columns)), fill_value=mask_value) # pad\n","        idx = data_matrix.shape[0] - df.shape[0]\n","        data_matrix[idx:,:] = df[columns].values  # fill with available data\n","    else:\n","        data_matrix = df[columns].values\n","        \n","    # specifically yield the last possible sequence\n","    stop = num_elements = data_matrix.shape[0]\n","    start = stop - sequence_length\n","    for i in list(range(1)):\n","        yield data_matrix[start:stop, :]\n","def gen_test_label_wrapper(df, sequence_length, label, ids=np.array([])):\n","    if ids.size <= 0:\n","        ids = df['id'].unique()\n","    \n","    label_gen = [gen_labels(df[df['id']==id], sequence_length, label) \n","                for id in ids]\n","    # keep only last window\n","    if sequence_length > 31:\n","      print(\"Too big window\")\n","    else:\n","      last_labels = [label[-1] for label in label_gen] \n","      \n","\n","\n","\n","    last_labels = np.concatenate(last_labels).astype(np.float32)\n","    # return label_array\n","    return last_labels\n"],"metadata":{"id":"tTAYBQ9yOOFV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sequence_length = 20\n","\n","gss = GroupShuffleSplit(n_splits=1, train_size=0.80, random_state=42)\n","\n","\n","for train_unit, val_unit in gss.split(train_set['id'].unique(), groups=train_set['id'].unique()):\n","    train_unit = train_set['id'].unique()[train_unit]  # gss returns indexes and index starts at 1\n","    val_unit = train_set['id'].unique()[val_unit]\n","\n","    train_split_array = gen_data_wrapper(train_set, sequence_length, feature_cols, train_unit)\n","    train_split_label = gen_label_wrapper(train_set, sequence_length, ['fail_30'], train_unit)\n","    \n","    val_split_array = gen_data_wrapper(train_set, sequence_length, feature_cols, val_unit)\n","    val_split_label = gen_label_wrapper(train_set, sequence_length, ['fail_30'], val_unit)\n","\n","# create sequences train, test \n","X_train = gen_data_wrapper(train_set, sequence_length, feature_cols)\n","y_train = gen_label_wrapper(train_set, sequence_length, ['fail_30'])\n","\n","test_gen = (list(gen_test_data(test_set[test_set['id']==id], sequence_length, feature_cols, -99.))\n","           for id in test_set['id'].unique())\n","X_test = np.concatenate(list(test_gen)).astype(np.float32)\n","\n","y_test = gen_test_label_wrapper(test_set, sequence_length, ['fail_30'])\n"],"metadata":{"id":"eOqZ7XIYFoRV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XjeFk9LvdYmj","executionInfo":{"status":"ok","timestamp":1643402710237,"user_tz":-120,"elapsed":17,"user":{"displayName":"return 0;","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN3tMOj_-g1ogwXC98E7gl1-D32a9_FPyIXLw0=s64","userId":"06352786353642446060"}},"outputId":"864f1abb-aa1d-466f-9965-14896202a168"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n","       1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n","       1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1.,\n","       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n","       0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.],\n","      dtype=float32)"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["# Defining custom dataset class for convenience\n","\n","class CustomDataset(Dataset):\n","    \n","    def __init__(self, X_data, y_data):\n","        self.X_data = X_data\n","        self.y_data = y_data\n","        \n","    def __getitem__(self, index):\n","        return self.X_data[index], self.y_data[index]\n","        \n","    def __len__ (self):\n","        return len(self.X_data)"],"metadata":{"id":"8VGDuaNy7e4f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize custom datasets\n","\n","train_data = CustomDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","test_data = CustomDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test))"],"metadata":{"id":"nii7SSoH8GO1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize dataloaders\n","\n","train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=False)\n","test_loader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)"],"metadata":{"id":"kdFMKvh39BaO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i,j in train_loader:\n","  print(i.shape,j.shape)"],"metadata":{"id":"rLDu2uqWgkOw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class BinaryClassification(nn.Module):\n","    def __init__(self):\n","        super(BinaryClassification, self).__init__()\n","        self.num_features = 18\n","        self.hidden_units = 32\n","        self.num_layers = 1\n","\n","        self.lstm = nn.LSTM(\n","            input_size=self.num_features,\n","            hidden_size=self.hidden_units,\n","            batch_first=True,\n","            num_layers=self.num_layers) \n","        \n","        self.linear = nn.Linear(in_features=self.hidden_units, out_features=1)\n","\n","        self.tanh = nn.Tanh()\n","        # self.sigmoid = nn.Sigmoid()\n","        \n","    def forward(self, x):\n","      batch_size = x.shape[0]\n","      h0 = torch.zeros(self.num_layers, batch_size, self.hidden_units).requires_grad_()\n","      c0 = torch.zeros(self.num_layers, batch_size, self.hidden_units).requires_grad_()\n","      _, (hn, _) = self.lstm(x, (h0, c0))\n","      out = self.linear(hn[0]).flatten()  # First dim of Hn is num_layers, which is set to 1 above.\n","\n","      return out\n","        # x, (hn, cn) = self.lstm1(inputs)\n","        # x = self.linear(x)\n","        # x = self.tanh(x) \n","        # return x"],"metadata":{"id":"ejWud_ptEcVq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P1KO5MfgOnr1","executionInfo":{"status":"ok","timestamp":1643402712046,"user_tz":-120,"elapsed":23,"user":{"displayName":"return 0;","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN3tMOj_-g1ogwXC98E7gl1-D32a9_FPyIXLw0=s64","userId":"06352786353642446060"}},"outputId":"f69dd43d-9fe5-47d2-9634-c8d50e768eb5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cpu\n"]}]},{"cell_type":"code","source":["EPOCHS = 20\n","LEARNING_RATE = 0.001"],"metadata":{"id":"e8Lf7B5sObKF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = BinaryClassification()\n","model.to(device)\n","print(model)\n","criterion = nn.BCEWithLogitsLoss()\n","optimizer = optim.Adam(model.parameters())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y1iSUwZmMiiC","executionInfo":{"status":"ok","timestamp":1643402712048,"user_tz":-120,"elapsed":15,"user":{"displayName":"return 0;","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN3tMOj_-g1ogwXC98E7gl1-D32a9_FPyIXLw0=s64","userId":"06352786353642446060"}},"outputId":"c2698ace-3890-480a-84dc-0db86c3a37a3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["BinaryClassification(\n","  (lstm): LSTM(18, 32, batch_first=True)\n","  (linear): Linear(in_features=32, out_features=1, bias=True)\n","  (tanh): Tanh()\n",")\n"]}]},{"cell_type":"code","source":["def binary_acc(y_pred, y_test):\n","    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n","\n","    correct_results_sum = (y_pred_tag == y_test).sum().float()\n","    acc = correct_results_sum/y_test.shape[0]\n","    acc = torch.round(acc * 100)\n","    \n","    return acc"],"metadata":{"id":"nmFmHuU6O6hx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Model training\n","\n","model.train() #tells pytorch that we are in training mode\n","\n","y_pred_train_list = []\n","\n","for e in range(1, EPOCHS+1):\n","    epoch_loss = 0\n","    epoch_acc = 0\n","    for X_batch, y_batch in train_loader:\n","        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n","\n","        optimizer.zero_grad()\n","        \n","        \n","        y_pred = model(X_batch)\n","\n","\n","        y_train_pred = torch.sigmoid(y_pred)\n","        y_pred_tag = torch.round(y_train_pred)\n","        y_pred_train_list.append(y_pred_tag.cpu().detach().numpy())\n","        loss = criterion(y_pred, y_batch.view(-1))\n","        acc = binary_acc(y_pred, y_batch.view(-1))\n","        \n","        loss.backward()\n","        optimizer.step()\n","        \n","        epoch_loss += loss.item()\n","        epoch_acc += acc.item()\n","        \n","\n","    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')\n","\n","y_pred_train_list = [a.squeeze().tolist() for a in y_pred_train_list]\n","y_pred_train_list = [item for sublist in y_pred_train_list for item in sublist]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AWqMx9BlPO9Y","executionInfo":{"status":"ok","timestamp":1643402773356,"user_tz":-120,"elapsed":61318,"user":{"displayName":"return 0;","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN3tMOj_-g1ogwXC98E7gl1-D32a9_FPyIXLw0=s64","userId":"06352786353642446060"}},"outputId":"7b5b9815-a148-4cf2-ca4e-2e6be19fb86e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 001: | Loss: 0.30820 | Acc: 88.399\n","Epoch 002: | Loss: 0.18107 | Acc: 93.355\n","Epoch 003: | Loss: 0.15731 | Acc: 93.928\n","Epoch 004: | Loss: 0.14557 | Acc: 94.276\n","Epoch 005: | Loss: 0.13700 | Acc: 94.614\n","Epoch 006: | Loss: 0.12879 | Acc: 94.891\n","Epoch 007: | Loss: 0.12241 | Acc: 95.082\n","Epoch 008: | Loss: 0.11755 | Acc: 95.239\n","Epoch 009: | Loss: 0.11366 | Acc: 95.379\n","Epoch 010: | Loss: 0.11032 | Acc: 95.451\n","Epoch 011: | Loss: 0.10762 | Acc: 95.608\n","Epoch 012: | Loss: 0.10491 | Acc: 95.710\n","Epoch 013: | Loss: 0.10200 | Acc: 95.805\n","Epoch 014: | Loss: 0.09946 | Acc: 95.990\n","Epoch 015: | Loss: 0.09749 | Acc: 96.075\n","Epoch 016: | Loss: 0.09531 | Acc: 96.188\n","Epoch 017: | Loss: 0.09276 | Acc: 96.283\n","Epoch 018: | Loss: 0.09073 | Acc: 96.317\n","Epoch 019: | Loss: 0.08869 | Acc: 96.375\n","Epoch 020: | Loss: 0.08828 | Acc: 96.392\n"]}]},{"cell_type":"code","source":["# Model testing\n","\n","model.eval()\n","\n","y_pred_test_list = []\n","\n","\n","with torch.no_grad():\n","\n","  test_loss = 0\n","  test_accuracy = 0\n","\n","  for X_batch, y_batch in test_loader:\n","        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n","        \n","        y_test_pred = model(X_batch)\n","        \n","        y_test_pred = torch.sigmoid(y_test_pred)\n","        y_pred_tag = torch.round(y_test_pred)\n","        y_pred_test_list.append(y_pred_tag.cpu().numpy())\n","        \n","        loss = criterion(y_pred_tag, y_batch.view(-1))\n","        acc = binary_acc(y_pred_tag, y_batch.view(-1))\n","        \n","        test_loss += loss.item()\n","        test_accuracy += acc.item()\n","\n","y_pred_test_list = [a.squeeze().tolist() for a in y_pred_test_list]\n","y_pred_test_list = [item for sublist in y_pred_test_list for item in sublist]\n","\n","\n","print(f'Test set evaluation : | Loss: {test_loss/len(test_loader):.5f} | Acc: {test_accuracy/len(test_loader):.3f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VGd5PZhStNsA","executionInfo":{"status":"ok","timestamp":1643402773357,"user_tz":-120,"elapsed":44,"user":{"displayName":"return 0;","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN3tMOj_-g1ogwXC98E7gl1-D32a9_FPyIXLw0=s64","userId":"06352786353642446060"}},"outputId":"d6253f22-17f3-4d67-a130-2b209e88b279"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test set evaluation : | Loss: 0.62552 | Acc: 95.500\n"]}]},{"cell_type":"code","source":["print(classification_report(y_test, y_pred_test_list))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UVw3QCrOn6cJ","executionInfo":{"status":"ok","timestamp":1643402773359,"user_tz":-120,"elapsed":41,"user":{"displayName":"return 0;","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN3tMOj_-g1ogwXC98E7gl1-D32a9_FPyIXLw0=s64","userId":"06352786353642446060"}},"outputId":"27624809-1eed-4dfb-d3a1-959d2e49dbe5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","         0.0       0.99      0.96      0.97        75\n","         1.0       0.89      0.96      0.92        25\n","\n","    accuracy                           0.96       100\n","   macro avg       0.94      0.96      0.95       100\n","weighted avg       0.96      0.96      0.96       100\n","\n"]}]}]}